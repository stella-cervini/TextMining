# Classification vs Clustering: an example on malignant comments :cursing_face: :globe_with_meridians: :computer:
The Internet, once praised for its open communication and limitless knowledge, has paradoxically turned into a space tainted by malicious comments, including hate speech and personal attacks. These harmful messages have cast a dark shadow over online spaces, eroding safety and inclusivity. The impact of malicious comments goes beyond individual experiences, affecting the broader online ecosystem and hindering open and honest conversations.

The need for automated classification of malicious comments is emphasized as a crucial requirement to combat online abuse. Such technology has the potential to create a safer and more inclusive digital environment by identifying and removing harmful content. However, developing effective automated classification systems is challenging due to the diverse nature of malicious language and the context-dependent nature of natural language.

The project aims to provide an overview of malicious comments detection by comparing the results of two machine learning tasks: classification and clustering. Classification assigns data points to predefined categories, while clustering groups data points based on their similarity. Both techniques aim to extract patterns and insights from data, but they approach this task differently.

Given the challenges in classifying malicious comments, the project seeks to verify whether these comments contain specific patterns that can be automatically detected or if linguistic elements like irony play a significant role in biasing algorithmic results. By leveraging both classification and clustering techniques, the project aims to gain a comprehensive understanding of the online abuse landscape and explore the differences and similarities between the two methods.
